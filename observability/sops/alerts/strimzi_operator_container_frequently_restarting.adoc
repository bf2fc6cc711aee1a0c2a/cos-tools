// begin header
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:numbered:
:toc: macro
:toc-title: pass:[<b>Table of Contents</b>]
// end header
= Strimzi Operator Container Frequently Restarting

toc::[]

== Description

The purpose of this SOP is to describe the process of resolving the alert `StrimziOperatorContainerFrequentlyRestarting`.

// Include the following step in every alert SOP, changing required parts
The source of the alert is the `kube_pod_container_status_restarts_total` related to the `strimzi-cluster-operator` container.
It fires when the increase in the time series in the range vector is greater than 3 in the last hour: `increase(kube_pod_container_status_restarts_total{container="strimzi-cluster-operator"}[1h]) > 3`

When this alert triggers it means that in the past hour, strimzi operator has been restarted more that 3 times.

There may be a number of reason for this alert to be fired.

== Prerequisites

// Include the following steps in every alert SOP
* Access to the OSD cluster via either Kafka_SRE IDP or Backplane.
* Permission to run managed scripts on the cluster.
* The ID of the affected OSD. This is provided by the alert via a label. It should look something like this: `cluster_id = rhoc-stage`.

== Execute/Resolution

// Include this as the first step in every alert SOP
. Log in to the OSD cluster that generated the alert. You can identify the cluster by looking at the field `Source` in the alert.

. The *redhat-openshift-connectors-observability / Strimzi Operators* Grafana dashboard can help you to troubleshoot the issue.

. Identify the reason why the Strimg Operator keep restarting.
. If the alert is not resolved move to the Troubleshooting section below.
. If a workaround is applied, open an issue for further investigations.

== Validate

What steps are required to verify that the procedure has been followed correctly and the required changes have been implemented correctly, with the desired outcome.

. Check the alert is no longer firing.
. Check the dashboard are shows a regression of Failed Reconciliations per Hour.

== Troubleshooting

* Check how may times the strimzi-cluster-operator has been restarted, es example:
+
[source]
----
➜ kubectl get pods strimzi-cluster-operator-6ddcb45f47-2jpp2
NAME                                        READY   STATUS    RESTARTS      AGE
strimzi-cluster-operator-6ddcb45f47-2jpp2   1/1     Running   4 (18m ago)   3d20h
----

* Check events to determine the reason of the restart:
+
[source]
----
➜ kubectl get events
LAST SEEN   TYPE      REASON               OBJECT                                                  MESSAGE
92m         Warning   Unhealthy            pod/cos-fleetshard-operator-debezium-59b9c9bd64-gj44t   Liveness probe failed: Get "http://10.131.0.68:8080/q/health/live": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
80m         Normal    Created              pod/strimzi-cluster-operator-6ddcb45f47-2jpp2           Created container strimzi-cluster-operator
14m         Warning   Unhealthy            pod/strimzi-cluster-operator-6ddcb45f47-2jpp2           Readiness probe failed: Get "http://10.131.0.67:8080/ready": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
29m         Warning   Unhealthy            pod/strimzi-cluster-operator-6ddcb45f47-2jpp2           Liveness probe failed: Get "http://10.131.0.67:8080/healthy": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
80m         Normal    Killing              pod/strimzi-cluster-operator-6ddcb45f47-2jpp2           Container strimzi-cluster-operator failed liveness probe, will be restarted
80m         Normal    Pulled               pod/strimzi-cluster-operator-6ddcb45f47-2jpp2           Container image "quay.io/strimzi/operator:0.28.0" already present on machine
14m         Normal    AllRequirementsMet   clusterserviceversion/strimzi-kafka-operator.v0.28.0    all requirements found, attempting install
14m         Normal    InstallSucceeded     clusterserviceversion/strimzi-kafka-operator.v0.28.0    waiting for install components to report healthy
14m         Normal    InstallWaiting       clusterserviceversion/strimzi-kafka-operator.v0.28.0    installing: waiting for deployment strimzi-cluster-operator to become ready: deployment "strimzi-cluster-operator" not available: Deployment does not have minimum availability.
14m         Normal    InstallSucceeded     clusterserviceversion/strimzi-kafka-operator.v0.28.0    install strategy completed with no errors
14m         Warning   ComponentUnhealthy   clusterserviceversion/strimzi-kafka-operator.v0.28.0    installing: waiting for deployment strimzi-cluster-operator to become ready: deployment "strimzi-cluster-operator" not available: Deployment does not have minimum availability.
14m         Normal    NeedsReinstall       clusterserviceversion/strimzi-kafka-operator.v0.28.0    installing: waiting for deployment strimzi-cluster-operator to become ready: deployment "strimzi-cluster-operator" not available: Deployment does not have minimum availability.
----
+
In this case, the operator got restarted because of the liveness probe failed.

* In this case, check the logs of the Strimzi operator pod.
+
[source]
----
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 2022-06-03 11:46:31 WARN  BlockedThreadChecker: - Thread Thread[vert.x-eventloop-thread-1,5,main] has been blocked for 2398 ms, time limit is 2000 ms
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 2022-06-03 11:46:31 WARN  BlockedThreadChecker: - Thread Thread[vert.x-eventloop-thread-1,5,main] has been blocked for 54706 ms, time limit is 2000 ms
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator io.vertx.core.VertxException: Thread blocked
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.BlockedThreadChecker.registerThread(BlockedThreadChecker.java:73) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.VertxImpl.lambda$createThreadFactory$21(VertxImpl.java:1079) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.VertxImpl$$Lambda$177/0x000000084021c840.newThread(Unknown Source) ~[?:?]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at java.util.concurrent.ThreadPoolExecutor$Worker.<init>(ThreadPoolExecutor.java:623) ~[?:?]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:912) ~[?:?]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1343) ~[?:?]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.TaskQueue.execute(TaskQueue.java:93) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.ContextImpl.executeBlocking(ContextImpl.java:170) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.WorkerExecutorImpl.executeBlocking(WorkerExecutorImpl.java:67) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.WorkerExecutorImpl.executeBlocking(WorkerExecutorImpl.java:71) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.strimzi.operator.common.operator.resource.ResourceSupport.executeBlocking(ResourceSupport.java:63) ~[io.strimzi.operator-common-0.28.0.jar:0.28.0]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.strimzi.operator.common.operator.resource.ResourceSupport.listAsync(ResourceSupport.java:265) ~[io.strimzi.operator-common-0.28.0.jar:0.28.0]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.strimzi.operator.common.operator.resource.AbstractResourceOperator.listAsync(AbstractResourceOperator.java:390) ~[io.strimzi.operator-common-0.28.0.jar:0.28.0]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.strimzi.operator.common.AbstractOperator.allResourceNames(AbstractOperator.java:466) ~[io.strimzi.operator-common-0.28.0.jar:0.28.0]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.strimzi.operator.common.Operator.reconcileAll(Operator.java:59) ~[io.strimzi.operator-common-0.28.0.jar:0.28.0]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.strimzi.operator.cluster.ClusterOperator.reconcileAll(ClusterOperator.java:156) ~[io.strimzi.cluster-operator-0.28.0.jar:0.28.0]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.strimzi.operator.cluster.ClusterOperator.lambda$start$1(ClusterOperator.java:124) ~[io.strimzi.cluster-operator-0.28.0.jar:0.28.0]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.strimzi.operator.cluster.ClusterOperator$$Lambda$326/0x0000000840457440.handle(Unknown Source) ~[?:?]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.VertxImpl$InternalTimerHandler.handle(VertxImpl.java:889) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.VertxImpl$InternalTimerHandler.handle(VertxImpl.java:860) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.EventLoopContext.emit(EventLoopContext.java:50) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.ContextImpl.emit(ContextImpl.java:274) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.EventLoopContext.emit(EventLoopContext.java:22) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.AbstractContext.emit(AbstractContext.java:53) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.EventLoopContext.emit(EventLoopContext.java:22) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.vertx.core.impl.VertxImpl$InternalTimerHandler.run(VertxImpl.java:883) ~[io.vertx.vertx-core-4.2.4.jar:4.2.4]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98) ~[io.netty.netty-common-4.1.71.Final.jar:4.1.71.Final]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:176) ~[io.netty.netty-common-4.1.71.Final.jar:4.1.71.Final]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) ~[io.netty.netty-common-4.1.71.Final.jar:4.1.71.Final]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469) ~[io.netty.netty-common-4.1.71.Final.jar:4.1.71.Final]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503) ~[io.netty.netty-transport-4.1.71.Final.jar:4.1.71.Final]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[io.netty.netty-common-4.1.71.Final.jar:4.1.71.Final]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty.netty-common-4.1.71.Final.jar:4.1.71.Final]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty.netty-common-4.1.71.Final.jar:4.1.71.Final]
strimzi-cluster-operator-6ddcb45f47-2jpp2 strimzi-cluster-operator 	at java.lang.Thread.run(Thread.java:829) ~[?:?]
I
----
+
In case you see something like `Thread blocked` as above, then the reason is likely related to garbage collection taking too much time to perform its task. Hence, the issue may be related to memory limits being too low.
+
This can be confirmed by looking at the various jvm entries in prometheus/grapahana, as example, you may get entries like the ones below:
[source]
----
action="end of major GC", cause="Metadata GC Threshold", container="strimzi-cluster-operator", endpoint="http", instance="10.131.0.67:8080", job="redhat-openshift-connectors-observability/strimzi-metrics", namespace="redhat-openshift-connectors", pod="strimzi-cluster-operator-6ddcb45f47-2jpp2"
action="end of minor GC", cause="Allocation Failure", container="strimzi-cluster-operator", endpoint="http", instance="10.131.0.67:8080", job="redhat-openshift-connectors-observability/strimzi-metrics", namespace="redhat-openshift-connectors", pod="strimzi-cluster-operator-6ddcb45f47-2jpp2"
----

* As workaround, the limits of the strimzi operator can be temporarly changed by changing them in the operator's CSV

// Include the following step in every alert SOP
* If the above hasn't worked contact engineering:
** Use the Managed Connectors Service Gchat channel during business hours.
** Use the #rhoc-support slack channel during business hours.